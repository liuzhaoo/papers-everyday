## 摘要wei



视频动作识别广泛应用于视频检索，智能监控，多媒体理解以及其他领域。近年来，通过引入卷积神经网络对深度信息的学习，该算法得到了极大的改进。这驱使我们回顾了有名的基于CNN的动作识别工作。由于CNN主要设计来从静止图像中提取二维空间特征，视频自然被视为3维信号，因此将CNN从图像扩展到视频的核心问题是时间信息的挖掘。我们将开发时间信息探索的解决方案分为三种策略：1）3D CNN；2）将与动作有关的信息作为CNN 的输入；3）融合。在本文中，我们根据这些策略对基于CNN的动作识别方法进行了全面的综述。我们还讨论了动作识别在最近的大规模基准的性能和基于CNN的行为识别的局限性以及未来的研究方向。本文对基于CNN的行为识别进行了客观而清晰的综述，并为今后的研究提供了指导。

## 1. 引言

识别和理解人类的行为和意图在机器人技术、人机交互、智能监控等领域是至关重要的，而且因此成为了一个重要且流行的研究课题。在过去的几十年中，大量的视频行为识别方法涌现出来。此外，各种行为识别数据集和标准也都发布了出来。2012年以来，卷积神经网络被广泛应用于图像领域，显著提升了图像分类，目标检测，场景分类的性能。CNN在图像领域的成功激起了其在视频行为检测上的研究。从图像扩展到视频的方法和CNN架构取得了显著成果。因此，基于CNN 的行为识别成为了一个热门的研究领域，近年来出现了大量基于CNN的方法，这些方法也取得了很大的成功。

如图一所示，视频行为识别分为两种任务：将视频分给一组事先定义好的动作类别中，以及在视频中定位实现定义好的动作，这两个任务分别叫分类和检测。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/分类和检测.png" style="zoom:67%;" />

与可视视频（灰度或RGB视频）相比，深度视频对光照不敏感并且可以捕捉物体的几何信息，而红外热成像视频对池成像光，光照变化等具有鲁棒性。此外，通过部署多目摄像头，可以从不同视角获取信息，从而使行为识别更加准确。因此，在深度视频，红外热成像视频和多角度视频中的行为识别获得了很大关注，而且在这些方向已经有了应用。

很明显，基于CNN的行为识别可以从可视视频扩展到深度视频和红外视频，从单视角到多视角。分类作为最基本和重要的任务，已经被广泛、深入地研究过，现在被归入检测的任务中。因此，这篇综述重点说明了可视单目视频中的动作分类任务。

本文按以下结构做了基于CNN的行为识别综述：第2节介绍先前的综述工作，第3节从手工方法和深度学习方法对行为识别做了综述。第4节根据挖掘时间信息的解决方案全面回顾了基于CNN的行为识别。第5节介绍当前发布的大规模行为识别数据集并且讨论了在这些标准上基于CNN 的动作识别的表现。最后，第6章总结CNN动作识别的局限性和未来的研究方向。



## 2.此前的综述工作

目前已经有很多文献对行为识别做了综述，有些作品明显包括最近的行为识别方法。有的文献专门讨论了行为识别的数据集和标准。本节我们介绍2014年以来发表的行为识别方向的综述。

。。。

介绍综述，就不翻译了



## 3. 行为识别综述

典型的行为识别分为两步：动作表征和分类。动作表征，也就是特征提取，被认为是行为识别的核心。高效的动作表征应该有以下特点： 1）有区别度：来自相同类的动作表征携带相似的信息，而来自不同类的动作表征携带不同的信息。2）效率：动作特征容易计算。 3）低维：这会使分类的成本低并且节省特征

图二表示了基于动作特征的行为识别分类，将行为识别分为手工表示和深度学习表示的方法，分别从视频中提取已经设计好的特征和可训练的特征，这两种方法的框架见图三

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/行为识别分类.png" style="zoom:67%;" />

<center>图二</center>

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/手工和深度.png" style="zoom:67%;" />

<center >图三</center>

对行为识别的研究开始于80年代对整体表征的研究，这种方法提取全局特征，比如基于轮廓的特征和基于光流的特征。然而，由于摄像头的抖动或运动，这种方式有一定的限制，需要进行背景背景减影，前景提取，定位和跟踪等预处理。2003年以来，局部表征的方法在行为识别上表现良好，这种方式直接从感兴趣点中提取特征，从而避免了预处理。手工表示的方法是行为识别中的一个里程碑。有关改进密集轨迹（IDT）的相关工作，这些研究使用Fishier vector(FV)或者超混合向量（HSV）来编码提取的密集轨迹、轨迹对齐HOG、HOF、和MBH，从而实现了手工表征行为识别的最好性能，而且经常用作评估新的额深度学习方法的标准。

不同于手工表示的方法，手工表示是使用手工设计好的特征，深度学习表征方法自动在视频中学习可训练的特征。图二给出了基于深度学习分类的深度学习行为识别类别。在计算机视觉的各个领域，包括行为识别基于深度学习的方法是目前研究的最多的方法，并且已经取得了很大的成功。除了CNN，其他的深度学习方法也被应用到动作识别中，并取得了很好的效果，尽管它们目前还不是很流行。这里，我们给出了每个类别的例子。Taylor等人使用限制玻尔兹曼机来获取各种基于运动的动作特征；Baccouche等人提出了一种自动学习稀疏超时空特征的自编码模型；Chen等人使用深度信念网络模型从视频中学习恒定的时空特征；为了探索各种卷积时间特征池化结构并将视频作为帧的有序序列进行建模，veeriah等人采用循环神经网络（RNN）也就是长短时记忆（LSTM）来学习复杂的动态行为。此外，Le等人提出一种独立子空间分析（ISA）网络算法的扩展，来从视频中学习恒定的时空特征。

## 4. 基于CNN 的行为识别



卷积神经网络是一种生物学启发的多层感知的变体，是一种前馈人工神经网络。它包括一个输入层，一个输出层和多个隐藏层。隐藏层是卷积层、池化层或全连接层。卷积层对输入数据应用卷积操作并添加偏差，并将结果首先通过一个激活函数然后传递给下一层。池化层是一种非线性的下采样层。在卷积层和池化层之后，CNN中的高级推是在全连接层中进行的，全连接层的每个神经元都连接到前一层的激活函数。在第 $i$ 层的第 $j$ 个特征图（feature map）在$（x,y）$ 处的计算如公式（1）所示
$$
v_{il}^{xy} = \varphi(b_{i,j}+\sum_m\sum^{P_i-1}_{p=0}\sum^{Q_i-1}_{q=0}w^{p,q}_{i,j,m}v^{(x+p),(yz=q)}_{(i-1),m})
$$
$\varphi$ 是一个非线性函数（比如Tanh,Sigmod或者ReLU）激活函数，W是权重矩阵，P和Q 是卷积核的高和宽

1998年一个名为LeNet-5的CNN结构被设计出来用以识别文件中的数字。然而，CNN发展的一直很慢，直到2012年在图像分类上开始迅速发展。近年来，CNN在图像分类和目标检测方面有了显著的发展。各种CNN结构比如ZFNet,VGG,GoogLeNet,BN-Inception和 ResNets等涌现出来，这些CNN架构的预训练模型(权值)是通过对大规模数据集进行预训练得到的。对于新的小规模数据集或新程序，可以部署迁移学习以微调网络的预训练模型。收到CNN在图像领域的启发，研究人员开始将CNN应用于视频行为识别领域。一大批表现良好的基于CNN 的行为识别方法涌现出来。

CNN 主要应用于二维空间，而且在提取静态图片的空间信息方面很有优势。一些研究使用CNN提取空间信息，并将它当作作辅助线索，和手工特征iDT结合起来以实现最后的行为识别。然而，视频作为3维时空信号，CNN主要是用来提取空间特征的，所以CNN由于缺乏时间信息不适合应用于视频。因此，将CNN从图像扩展到视频的核心问题是对时间信息的利用。我们将时间信息开发的解决方案分为三种策略：1）3D CNN；2）将与动作有关的信息作为CNN 的输入；3）融合。事实上，这三种方法是互相重叠的，比如一种 3D CNN结构也使用运动信息作为它的输入。

### 4.1 3D 卷积

利用时空信息最直接的解决方案是对视频进行3D卷积，这在2012年之前的一些开创性的基于CNN 的动作识别作品中得到了验证。3D卷积是通过使用3D卷积核对视频片段进行卷积实现的。在第i个卷积层的第j个特征图上（x,y,z）处的运算如公式二：

$$
v_{il}^{xy} = \varphi(b_{i,j}+\sum_m\sum^{P_i-1}_{p=0}\sum^{Q_i-1}_{q=0}\sum^{R_i-1}_{r=0} w^{p,q,r}_{i,j,m}v^{(x+p),(y+q),(z+r)}_{(i-1),m})
$$
其中，R 是时间长度，2D卷积和3D卷积示意图如下：

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/2d&amp;3d.png" style="zoom:67%;" />



Ji等人设计了一个用于行为识别的3D CNN网络，是2012年之前重要的开创性作品之一，它有1个硬线层，3个卷积层，2个下采样层和一个全连接层，硬线层生成灰度通道，梯度通道和光流通道。之后，在每个通道中应用卷积和下采样，最后的行为识别是通过结合所有通道的信息计算得到的。最近Ji等人改进了他们的3D CNN 网络，将输出的高级特征正则化，并且结合了多种不同CNN 结构的预测。与此同时，Tran等人做了系统的研究来寻找3D CNN的最佳卷积核的时间长度而且开发了一种VGG风格的3D CNN结构，名为C3D。如图5所示，C3D结构使用了8个卷积层以及$3\times3\times3$  的小卷积核，5个池化层和两个全连接层。此网络提取到的特征经过证明是通用的，而且高效、紧凑。此外，Tran等人在深度残差网络中进行了3D CNN 的研究，开发了一种ResNet18风格的网络，名为Res3D,在识别精度方面优与C3D.相比C3D, Res3D在运行时快2倍，在尺寸上小2倍，而且更紧凑。通过在最大的行为识别数据集Sports-1M上进行预训练，作者提供了C3D和Res3D的预训练模型，这些模型既可以用作迁移学习的初始化，也可作为固定的时空特征提取器。不同于以上提到的工作（在7，16或8帧的视频切片上学习时空信息），Varol等人开发了一种长时间时间卷积结构（LTC）,该结构通过在更长一点的视频片段上（比如60或者100帧）部署3D CNN在全时间尺度上表示动作，而且证明了高质量光流作为LTC输入的重要性。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/C3D.png" style="zoom:67%;" />

<center>图5 C3D结构 红色，绿色，蓝色，黄色和紫色的长条分别代表卷积，标准化，池化，全连接和softmax层

训练3D CNN非常耗费算力和内存，使用2D CNN模拟或仿真3D CNN是3D CNN的另一种实现方式。为了减少网络参数的数量，缓解高核复杂度和训练视频数据不足的多种困难，Sun等人提出了一种分解时空卷积网络（FstCN）,将原始的三维卷积核学习分解为先学习低层的二维空间卷积核，然后再学习上层的一维时间卷积核。针对序列对齐的问题，他们还提出了一种有效的训练和推断策略，该策略基于对给定动作视频序列中的多个视频片段进行采样。

为了使用2D CNN 的技术，而不是从头开始训练3D CNN，Mansimov等人提出了几种使用2D卷积权重去初始化3D卷积权重的方法，包括包括平化、缩放、零权重和负权重初始化。实验结果表明，在所有初始化方法中，负权值初始化的性能最好。包含时间维度 $T$ 的3D卷积权重矩阵$w^{p,q,r}$ 是由D卷积权重矩阵$w^{p,q}$ 负权重初始化得到的：


$$
w^{p,q,r} = \alpha_t w^{p,q},\text {where} \ \ \ \  \alpha = \begin {cases}
\frac{2 T-1}{T}, \ \ \  \ \text {if  t=1}\\
-\frac1T, \ \ \ \ \text {otherwise}
\end{cases}
$$


通过将一个$3\times 3 \times 3$ 的3D卷积滤波器分解成一个$1\times3\times3$ 的卷积滤波器（相当于2D CNN）和一个$3\times1\times1$ 的卷积滤波器（1维 CNN），Qiu等人在残差网络中设计了三种瓶颈结构的block，并且提出了一种名为 P3D ResNet 的伪3D Residual50结构，在该结构中残差单元被不同的构建块所替代，如图六所示。为了追求深度网络设计中的结构多样性，这三种变体以交错顺序混合。与原始的3D CNN相比，这个伪3D CNN不仅大大减小了模型的尺寸，而且可以在图像数据集上使用2D CNN 预训练。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/P3D.png" style="zoom:67%;" />

<center>图六 三种结构

### 4.2 将运动相关的信息作为 CNN 的输入

为了利用时间信息，一些研究已经在试着将运动信息比如光流和运动向量作为CNN的输入。如图7所示的双流模型，将光流作为CNN的输入来提取运动信息，是一种流行而且重要的动作识别方法。根据视觉通路假说：腹侧流在对象的感知识别中起主要作用，而背侧流则针对此类对象的视觉引导动作介导了所需的感觉运动转换，simonyan等人提出了行为识别的双流模型，空间流在静止的帧中精心行为识别，训练时间流从运动信息中进行动作识别。该模型中的每条流都采用CNN架构来实现，通过后期融合(均值融合或SVM融合)将两种流的softmax得分进行合并，得到最终结果。每个流都采用CNN-2048结构。由于空间流的CNN 本质上是一种图像分类，他们在ImageNet数据集上预训练了空间CNN，又在测试集种对空间CNN进行了微调。时间CNN不像空间CNN那样，可以在大型分类数据集上预训练，它需要在更小的测试集上训练。为了防止过拟合，采用多任务学习来对时间CNN进行训练。然而，双流法在动作识别方面的改进并不明显。Wang等人通过比较两流法和静止图像中的物体识别，认为产生这一结果有两个原因 :一是选取的CNN结构太浅，二是训练集的规模太小。为了解决这些问题，他们采用了GoogLeNet和VGG-16深度CNN 结构设计了一个非常深的双流模型，同时在训练时做了一些改进，包括对两个流都进行预训练，使用更小的学习率，更多数据增强和高dropout率。这个很深的双流模型比原始的模型表现要好。为了最大化利用双流模型中的时空信息，Feichtenhofer等人研究了很多种在时空上融合两种流的方法，提出了一种一种改进的双流模型，该模型在两个流之间引入了一种新的卷积融合层和一个包含了3D 卷积和3D池化的新型时间融合层。这种池化和其他类型的池化的区别如图8所示。由于最近在非常深的网络训练中使用ResNet表现很好，Feichtenhofer等人也引入了时空ResNet，作为ResNet和双流法的组合：通过在空间流和时间流之间加入残差连接，从而可以对时空特征进行分层学习。此外，通过将预训练模型的维映射过滤器转换为时间卷积，将两个流从空间域转换到时空域，并随时间初始化为残差过滤器。在这个双流模型中，计算光流是最消耗算力的。Zhang等通过将光流替换为运动向量来加速该模型，运动向量可以直接从压缩视频中得到而无需额外计算。然而，运动向量缺乏精细的结构，并包含噪声和不准确的运动模式。为了解决这个问题，他们提出将从光流CNN学习到的知识转移到运动矢量CNN，即对运动向量进行训练。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/双流模型.png" style="zoom:67%;" />



<center>图7  双流模型 红、绿、蓝、黄、紫分别代表卷积、标准换、池化、全连接层和softmax层
<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/3D CON+3DPOLING.png" style="zoom:67%;" />



<center>图8 3D Conv + 3D Pooling与其他类型的比较 3D Conv + 3D Pooling在3D Pooling之前与一个跨越特征通道、空间和时间的融合内核进行卷积。

### 4.3 融合 

在利用时间信息时也用到了融合的的方法。人们提出了很多方法在时域中融合信息或者将帧级信息和片段级的信息聚合为视频级信息。Karpathy等人研究了几种连接模式在时间上融合空间信息：单帧融合，早期融合，后期融合和慢融合。这几种融合方式见图9.实验结果表明，慢速融合的性能优于早期融合和后期融合，但是和纯空间网络的单帧模型的性能相近。这些结果表明，这些融合方式不能捕获足够的运动信息。另外，Fao等人利用空间特征中的时间关联性引入了一种特征对齐来生成紧凑的视频表示，Yu等人试图通过分层池将CNN帧的空间特征融合到视频时空特征。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/fusion.png" style="zoom:67%;" />

<center>图9 通过融合空间信息来利用时间信息

融合是动作识别中的一个普遍概念，它不仅可以从空间特征中发掘时间信息，而且可以通过融合、聚合和合并各种提取到的信息比如空间、时间和时空信息来发掘信息，最终用于视频表示。比如上面提到时空融合，在改进的双流模型中的时间融合以及ResNet双流模型中空间流和时间流之间的残差连接。此外Feichtenhofer等人通过运动控制将ResNet双流模型中的空间和时间流结合起来，并使用identity mapping 卷积核作为时间滤波器，来学习长时间的时间信息。为了给动作识别中的CNN中寻找合适的时间特征合并，Ng等人研究了很多种时间合并方法，这些方法对在双流模型中提取的帧级别的空间和时间特征进行了研究，并且实验性地选择了时间最大池化作为行为识别的主要特征融合技术。不同于时间池化产生的动作的顺序不变的表征，他们还提出通过在时间特征和空间特征上使用LSTM以将动作表示维帧的有序序列，如图10所示。LSTM使用内存单元来存储、修改和访问内部状态，可以从提取的信息中发现长期的时间信息。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/useLSTM.png" style="zoom:67%;" />

<center>图10  使用LSTM来发掘长时间的时间信息

Srivastava等在编码器-解码器框架中对通过两流模型获得的特征采用了LSTM，Yao等人建议在编码器-解码器框架中使用3D CNN功能和LSTM解码器。

### 4.4 总结

在本节中，我们回顾了基于cnn的动作识别工作，这些工作是根据时间信息挖掘的解决方案进行的。三维CNN和两流方法是学习时空信息的重要方法。融合在基于cnn的动作识别是一个更普遍的概念，用于通过融合、汇集或聚合各种提取的信息来开发时空信息。

另外，从时间尺度来看，CNN提取的时空信息可以分为四类（从小到大）：空间信息，运动信息，短时间的时间信息以及长时间的时间信息。很显然空间信息，运动信息和短时时间信息分别可以使用帧中的CNN，光流CNN和3DCNN建模，长时时间信息的建模方式有多种。如上面提到的，它可以通过在提取到的深度特征中使用LSTM来建模，在长片段中使用长时时间3D卷积，或者将identity mapping 卷积核作为时间滤波器。

## 5.表现

在本节中，我们将介绍最近发布的大规模动作识别数据集。为了比较，我们通过在这些数据集上展示识别精度来说明动作识别的性能。

### 5.1 最近的大规模数据集

随着行动识别的改进，不同种类的基准和数据集已经发布。Hassner等人[14]提供了多年来发展起来的动作识别数据集的回顾:早期的实验室数据集，例如Weizmann [；电视中的临时数据集，比如UCF Sports，以及最近的数据集，例如UCF101。在本节中，我们介绍几个最近的大规模动作识别数据集。

HMDB51 [85]: HMDB51中的视频来自各种互联网资源和数字化电影，其中人类的动作是日常行为的代表。这个数据集中的一些关键挑战是摄像机视点和运动的巨大变化，杂乱的背景，位置、比例和演员的外观的变化。HMDB51包含51个不同的动作类别，每个类别至少包含101个片段，总共6766个视频片段。行为类别可分为五类:1）一般面部动作 ，2)面部动作与对象操作，3)一般身体动作，4)身体运动与物体相互作用;5）人之间的动作交互。对于每个动作类别，将视频剪辑分成70个片段的训练集和30个片段的测试集，实现了70/30平衡，训练集和测试集中的片段不能来自同一视频文件。这个数据集被标注了动作类别标签、视频质量和元信息，包括有形身体、下半身或全身、摄像机动作和参与动作的人数。

UCF101 : UCF101是UCF50数据集的扩展，来自YouTube，有13320个视频，101个行为类别。UCF101在动作方面提供了最大的多样性，并在摄像机运动、对象外观和姿态、对象规模、视点、杂乱的背景、照明条件等方面提供了巨大的变化，每个动作类别的视频分为25组，每组由4-7个动作视频组成。动作类别可分为五类:1)人与物的互动，2)仅身体动作，3)人与人的互动，4)乐器演奏，5)运动。建议分三次训练/测试;每此测试使用7个不同的组，剩下的18个组用于训练。

Sports-1M[71]:为了在视频领域获取足够数量的数据训练CNN架构，开发了Sports-1M数据集，它包含了带有487个类注释的100万个YouTube视频。每一类有1000-3000个视频，大约5%的视频不止标记了一类动作。数据集的分割方式是将70%的视频分配给训练集，10%分配给验证集，20%分配给测试集。与在ImageNet上预训练2D CNN模型一样[，3DCNN的预训练模型，如C3D和Res3D的预训练模型，是通过在Sports-1M上进行预训练得到的。

### 5.2 识别结果性能

由于数据规模较大，在Sports-1M数据集上评估的动作识别工作很少。我们在表一中展示了在Sports-1M数据集中基于CNN 的工作。HMDB51和UCF101数据集最近是评价动作识别方法的最流行的基准。我们在表2中提供了基于cnn的、在这两个数据集上有影响力或获得显著结果的研究成果的综合列表。对于每种方法，我们给出了识别精度、CNN架构和CNN的输入。为了与最先进的传统手工表示方法进行比较，我们列出了与idt相关的动作识别的结果。精度直接来自于原著。此外，我们还用红色标出了最先进的基于cnn的方法。

快速查看表2中的结果，可以发现UFC101实现的动作识别精度超过94%。然而，同样的方法在HMDB51上只能达到大约70%的精度，因为HMDB51存在较大的视点变化、杂乱的背景以及行动者位置、规模和外观的变化。这说明现有的动作识别方法无法克服这些挑战。另一方面，我们注意到早期基于cnn的作品表现不如与iDT有关的方法。随着CNN结构越来越深和新技术的采用，最近开发的基于CNN的方法有了明显的改进，其性能优于iDT相关的方法。

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/table12.png)



### 5.3 总结

从深层AlexNet和ZFNet到非常深的VGG和GoogLeNe再到非常深的ResNet，从C3D和LTC到Res3D再到P3D-ResNet，对基于CNN的行为识别使用的2D 和3D CNN 结构变得越来越深。这些结果表明，随着CNN深度的增加，识别性能得到了提高。另一方面，将RGB和光流都用作CNN的输入可提高识别的可靠性。通过仅关注RGB输入，我们可以确定为动作识别而提取时空信息的最强大的体系结构是P3D-ResNet，这是合理的。P3D-Res3D是一种极深的3D CNN架构，其性能优于极深的CNN架构以及极深的2D CNN架构。

## 6 总结

最近，基于cnn的动作识别在具有挑战性的数据集上取得了显著的性能，并优于手工表示方法，受到了计算机科学界的广泛关注。在图像领域，视频具有从二维空间提取空间信息的强大能力，因此视频自然被视为三维时空信号。在视频领域使用CNN的核心问题是对时间信息的挖掘。在本文中，我们总结了挖掘时间信息的解决方案，并根据这些解决方案对基于cnn的动作识别进行了综合评述。我们还提出并比较了基于cnn的动作识别方法在两个具有挑战性的数据集上的结果： UCF101和HMDB51。

最后对基于cnn的行为识别的局限性和未来的研究方向进行了总结。

虽然基于cnn的动作识别最近取得了显著的进展，但动作识别的挑战，如视点变化、遮挡等，仍然没有被克服。目前，由于缺乏系统完整的理论，很难解释CNN所提取的深层特征的含义。只有一些可视化技术可以洞悉中间特征层的功能以及分类器的操作。另一方面，现有数据集中的视频没有识别出动作识别的特定挑战，只有整体绩效才能被评价;动作识别方法对特定挑战的鲁棒性仍然无法评估。从本质上讲，很难从理论或评估的角度理解基于cnn的方法应对具体挑战的能力。CNN的一些负面性质也应该在这里得到解决。CNN是计算和内存密集型的。因此，CNN很难部署在硬件资源有限的嵌入式系统上。此外，基于cnn的方法依赖于大量的数据;然而，许多真实的场景缺乏足够的数据来进行训练，即使一些大规模的数据集已经被开发出来，使CNN架构的微调成为可能。

从改进行为识别的角度出发，展望了基于cnn的方法在未来的几个研究方向。3D CNN比2D CNN更适合时空特征学习。新兴的强大2D CNN架构应该迁移到3D CNN。光流作为输入有利于基于cnn的动作识别，这是一种流行的动作相关信息。然而，光流带来了很高的计算成本。应该对将新的有效的运动相关信息作为CNN的输入进行研究。融合作为一个普遍的概念，在基于cnn的动作识别中始终是一个关键字，它是通过融合、汇集或聚合各种提取出来的信息来利用时空信息。系统理论的探索是一个巨大的挑战。必须付出很大的努力来填补业绩和理论之间的差距。此外，还必须努力减少CNN对资源的需求，将基于CNN的方法用于小数据集。所有这些预期的研究方向集中在解决时空信息开发和减轻上述局限性中。

