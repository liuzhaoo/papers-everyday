### 摘要

之前的目标检测使用分类器来执行检测。但是我们将目标检测看作是空间分离的边界框和相关的类的概率的回归问题。一个单独的网络在一次测试中直接从完整的图像中预测边界框和类别的概率。由于整个检测过程是一个单一网络，因此可以对其检测性能进行端到端的直接优化。

基础模型一秒可以处理45帧图像，Fast版本更快同时mAP可以达到其他检测器的两倍。与sota模型相比，YOLO有更多的局部误差，但是不会预测出假阳性。

### 引言

当前的检测系统使用分类器来执行检测，为了检测一个目标，这些系统对该目标进行分类，并在测试图像的不同位置和尺度上对其进行评估。像DPM这样的系统，使用滑动窗口的方法，将分类器在整个图像中均匀间隔的位置上运行。

R-CNN使用候选区域的方法，首先在图像中生成可能是目标的边界框，然后在这些候选区域上进行分类。分类完成后，通过后处理对边框进行细微调，消除重复的检测，并根据场景中其他物体对边框重新打分。这些复杂的过程速度很慢，而且很难优化，因为每个单独的组件都必须单独训练。

我们将目标检测重构为一个单一的回归问题，直接从图像像素到边界盒坐标和类概率。

YOLO：使用一个卷积网络同时预测多个边界框和这些边框对应的类别概率。YOLO在全图像上训练并且直接优化检测性能

与传统的目标检测方法相比，这种统一的模型有几个优点：

1. 非常快，同时YOLO达到了其他实时系统平均精度的两倍以上。
2. YOLO在做预测的时候从整体上对图片进行分析。不像滑动窗口和候选区域的方法，YOLO在训练和测试时是针对整个图像，因此它隐式地编码有关类及其外观的上下文信息。Fast R-CNN将图像中的背景补丁错误地当成物体，因为它看不到更大的背景。YOLO产生的背景错误少于Fast R-CNN的一半。
3. YOLO学习对象的通用的表征，当在自然图像上训练并在艺术品中测试时，性能仍然很好。

YOLO在准确度方面仍然落后于最先进的检测系统。虽然它可以快速识别图像中的物体，但它很难精确定位一些物体，特别是小物体。我们在实验中进一步研究了这些权衡

### 2. 整体的检测

我们将目标检测的各个部分统一到一个单一的神经网络中，我们的网络使用来自整个图像的特征来预测每个边界框。它还可以同时预测图像中所有类的所有边框。这意味着我们的网络在整体范围内对整个图像和图像中的所有对象进行分析。

将输入分为$S\times S$ 的网格。如果一个物体的中心落在一个网格里，这个网格就负责检测这个物体。

每个网格预测B个边界框和这些框的信心分数。这些分数反映了模型对边框里有一个物体的置信程度，也反映了模型对边框预测的准确度。我们将此置信度定义为$Pr(Object)*IOU^{truth}_{pred}$  。如果网格内没有物体，分数为0。否则就令此分数等于预测的边框和真实边框的交并比。

每个边界框包括5个预测内容：$x,y,w,h$ 以及置信度。$(x,y)$ 坐标表示相对于这个网格边界的box的中心。宽度和高度是相对于整个图像的预测值。置信度则表示预测的框与实际框的IOU。

每个网格还预测C类条件概率$P_r(Class_i|Object)$ ，即在确定有物体的条件下，它是第i类物体的概率。每个单元格只预测一类物体的概率，不管它包含有多少B个框。所以，每个网格预测的内容有$(B*5+C)$ 个，C是总的类别

测试时，我们将条件概率与单个边界框置信度相乘
$$
P_r(Class_i|Object)*Pr(Object)*IOU^{truth}_{pred}
$$
这就得到了每个边界框是特定类的信心分数。这些分数编码了该类出现在方框中的概率，以及预测的方框与对象的匹配程度。

#### 2.1网络的设计

网络的初始卷积层从图像中提取特征，而全连接层则预测输出概率和坐标。

网络受到了GoogLeNet的启发，有24个卷积层以及两个全连接层。没有使用GoogLeNe用到的Inception模块，我们使用了1x1的下降层，后跟3x3的卷积层。如图所示。

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/yolo1.png)

我们还训练了一个YOLO的快速版本，旨在突破快速对象检测的边界，Fast YOLO使用的神经网络具有较少的卷积层(9层而不是24层)和较少的过滤器。除了网络的大小，YOLO和Fast YOLO的所有训练和测试参数都是相同的。

我们网络的最终输出是预测的7x7x30张量（s=7，B=2, C=20）

#### 2.2 训练

先用前20层（后跟平均池化和全连接层）对数据进行训练，得到了不错的性能。

然后我们转换模型进行检测。Ren等人表明，在预先训练好的网络中同时添加卷积层和连接层可以提高性能。对后4个卷积层和全连接层的权重随机初始化，加到网络里。检测通常需要细粒度的视觉信息，因此我们将网络的输入分辨率从224 224增加到448 448。

最后一层预测类概率和边界框坐标。我们按照图像的宽度和高度对边界框的宽度和高度进行标准化，使它们介于0和1之间。我们将边框x和y坐标参数化为特定网格单元格位置的偏移量，因此它们也被限定在0和1之间。

我们对最后一层使用线性激活函数，其他所有层使用非线性。



为避免过拟合，使用了dropout和数据增强。为避免多个cell预测同一个物体，使用非极大值抑制

对输出的平方和误差进行优化。我们使用平方和误差，因为它很容易优化，但它不能完全符合我们最大化平均精度的目标。定位误差与分类误差的权重相等，分类误差可能并不理想。此外，在每幅图像中，许多网格单元格不包含任何对象。这会使这些单元格的置信度分数为零，通常会覆盖包含对象的单元格的梯度。这可能导致模型不稳定，导致训练在早期就出现分歧。

为了弥补这一点，我们增加了边界框坐标预测的损失，并减少了对不包含对象的框的信心预测的损失，使用两个参数$\lambda_{coord},\lambda_{noobj}$ 分别设置为5和0.5.

 平方和误差对大边框和小边框的误差的权重也是相等的，我们的误差度量应该反映出小边框里的小偏差比大边框里的小偏差更重要。为了部分解决这个问题，我们预测边界框的宽度和高度的平方根，而不是直接的宽度和高度。

YOLO的每个网格预测多个边界框，在训练时，我们只需要一个边界框预测器来对每个对象负责，即每个网格预测一种物体。