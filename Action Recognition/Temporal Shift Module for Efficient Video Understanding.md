###  摘要

在线视频的爆炸式增长对有效提取时空信息以进行视频理解提出更大的挑战,2D CNN比较节省算力但是无法捕捉长时间的时间信息；基于3D CNN的方法可以取得很好的性能，但是需要很大的算力，使得部署成本高昂。本文提出了一种通用的、高效的时移模块(TSM)，可以同时具有高效率和高性能。体来说，它可以在保持2D CNN复杂度的前提下实现3D CNN的性能。TSM的核心思想是沿时间维度移动部分通道，这有利于相邻帧之间的信息交换。可以将TSM插入到2D CNN中，以零延迟和零参数的代价实现时序建模。此方法相比 I3D，C3D等方法都在精度和FLOPs方面有很大提高。

### 1. 引言

计算效率的视频理解对于真实世界的部署非常重要，无论是云端还是线下。比如，YouTube每天有大量视频上传，需要对这些视频进行处理来进行推荐和广告排名；院中字节级的敏感视频需要在边缘上进行本地处理，以保护隐私。所有这些工业应用都需要精确和高效的视频理解。

多年来，深度学习已经成为视频理解的标准。视频识别和图像识别的一个关键区别是需要时间建模。例如，为了区分打开和关闭一个盒子，不同的顺序会造成相反的结果。一种进行视频理解的直接方法是直接使用2D CNN。然而2D CNN使用的是单独的帧，无法建模时间信息。3D CNN可以联合学习时空特征，而3D CNN的计算代价较大，制作部署昂贵。已有研究在时间建模能力和计算能力之间进行权衡，如post-hoc融合和mid-level时间融合.这种方法牺牲了低层次的时间建模来提高效率，但在时间融合之前的特征提取过程中，大量有用的信息丢失了

在本论文中，我们提出了一种0FLOP，0参数的时序转换模块，可以将它插入到任何2DCNN来进行时序建模。对于一个视频模型中的激活函数$A\in \mathbb R^{N \times C \times T \times H \times W}$ ，其中N是batch_size，C是通道数，T是时间维度，H和W是空间分辨率。2D CNN 只在T维度上操作，因此没有时间建模。我们的时间转换模块在前向传播和后向传播中沿着时间维度转移通道。如图2所示，相邻帧的信息在移动后与当前帧的信息混合。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/TSM-moudel.png" style="zoom:80%;" />

*说明：* a图：未进行时间融合的原始tensor，第$i$行只包含$T_i$ (时序上第$i$个帧 )的特征图。 b图：进行了时间偏移的tensor（zero padding）。第$i$行包含$T_i，T_{i+1}$和$T_{i-1}$ 维度上的特征图（除了边界）。c图：使用循环填充的偏移。

这是时序移位模块，对于2D CNN来说，这是在不同的帧上独立运行的（每个帧是具有相同颜色的一行）。而与我们的时间移位模块，相邻的三帧混合在一起(多颜色每行)。时域移位模块具有零参数开销，零计算开销，同时有效地混合了相邻帧的时域信息。



我们的直觉是:卷积运算由移位和乘积累加组成。在时间维度上进行正负1的移位，并且将乘积从时间维度折叠到通道维度。这等效为卷积核3的时域卷积。在实现时，我们只需要移动地址指针，而不需要移动数据，从而保证了效率。

我们将时序移位模块插入ResNet来构建TSM视频模型。将视频分为N等份，并从每一份中取出一帧。这样可以使采样的帧横跨整个视频。然后对每一帧应用2D CNN提取空间特征。在每个2D残差块中，时序移位模块都会沿着时间维度将一部分通道移动正负1个维度来融合时间信息。然后移位了的激活就会被后面的2D卷积沿着通道维度处理。我们发现，将时间移位模块插入到残差分支比插入到残差的外部更好，因为这样不会损害2D CNN骨干网的空间特征学习能力。我们还添加了一个额外的时间最大池化层来减少时间维数，与纯2D CNN相比，实现了的更少的计算量。

作者做了大量的实验，结果如图：

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/tsm-better.png" style="zoom:80%;" />

无论是精度还是效率方面，对比之前的网络都有很大提升。

### 2. 相关工作

#### 2.1 深度视频识别

**2D CNN.** 使用2DCNN进行视频识别时一种直接的方法。比如Simonyan等人实际了一种双流网络，分别以RGB和光流做为输入。时域分割网络（TSN）从跨步的采样帧中提取平均信息。这些方法相比s3D网络效率更高。但是，由于所得到的特征是用加权平均或简单平均池法进行融合，模型无法推断出时间顺序或更复杂的时间关系。

**3D CNN.** 三维卷积神经网络可以联合学习时空特征。比如C3D。但是这这方法十分耗费算力，参数也比2D的多，容易过拟合。另一方面来货，我们的TSM具有与3D CNN相同的时空建模能力，同时具有与2D CNN相同的计算量和参数。

**Trade-offs. ** 也有人进行了两者的权衡，Tran等提出将2D和3D卷积混合到一起。也有人提出分解3D卷积的时空维度，使用1D卷积和2D卷积来代替3D卷积

#### 2.2 时序建模

对长时间的时序建模是一种挑战。一种直接的方法是使用上面讨论的基于3D CNN的方法。另一种建模时间关系的方法是使用二维CNN +后hoc融合。还有些作品引入了LSTM聚合CNN的特征用于视频识别。注意机制在时态建模中也被是有效的。Zhou的人提出时间关系网络（Temporal Relation Network）来学习和推理视频帧之间的时间依赖性。

#### 2.3 高效的深度模型

2D CNN的效率已经得到了广泛的研究。有些作品专注于设计一种高效的模型，另一种方法是压缩或量化现有模型以实现高效部署。地址移位，这是一个硬件友好的原语，也被开发来进行紧凑的二维CNN设计的图像识别任务。然而，建立一个有效的视频理解深度模型受到的关注相对较少。在本文中，我们提出了一个高效的模块，使任何一个 2D CNN都能高效地进行时空特征学习用于视频识别，使视频理解也能从之前高效二维CNN的努力中受益。

### 3 .方法

本节首先描述用于时态建模的TSM，然后展示怎样使用它来建立TSM视频模型以进行高效的长时间视频理解。

3.1