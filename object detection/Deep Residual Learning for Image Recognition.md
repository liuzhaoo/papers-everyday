### 摘要 

深度神经网络更难训练。我们提出了一种残差学习框架，来简化那些比以前使用的更深的网络的训练。我们根据层的输入把这些层显式地改造成学习残差函数，而不是而不是学习未引用的函数。我们提供了全面的经验证据，表明这些剩余网络更容易优化，并能从大幅度增加的深度中提高精度。我们在Image数据集上评估了深达152层的残差网络---这比VGG网络还要深8倍但是仍有很低的复杂度。这些残差网的集合在ImageNet测试集上的误差达到了3.57%。这些结果在ILSVRC 2015分类任务中赢得了第一，我们还在CIFAR-10上进行了100和1000层的分析。

表征的深度在很多视觉识别任务中都是最重要的。由于我们很深的表示，我们在COCO对象检测数据集上获得了相对28%的改进。深度残差网络是我们向ILSVRC和COCO 2015竞赛提交资料的基础，我们在ImageNet检测，ImageNet定位，COCO检测和COCO分割任务上也获得了第一名

### 1. 引言

深度卷积神经网络在图像分类方面取得了一系列突破，深度网络自然地以端到端多层的方式将低/中/高层特性和分类器集成在一起，而且特征的“层次”可以通过堆叠层的数量（深度）而得到丰富。最近有论文证明网络深度是至关重要的，而且在ImageNet数据集挑战方面的一些领导性的结果都使用了非常深的模型，深度从16层到30层都有。许多其他重要的视觉识别任务中也从非常深的模型中受益。

在深度的驱动下，一个问题出现了：学习更好的网络就像堆叠更多层那样简单吗？回答这个问题的一个阻碍就是梯度消失和梯度爆炸问题，这从一开始就阻碍了收敛。然而，这个问题已经通过标准化初始化和中间的归一化层得到了最大程度的解决，这使具有数十层的网络开始收敛于具有反向传播的随机梯度下降(SGD)。

当更深层次的网络能够开始收敛时，一个退化问题就暴露出来了：随着网络深度的增加，精确度会达到饱和(这可能并不令人惊讶)，然后迅速下降。出乎意料的是，这种退化并不是由过拟合引起的，在适当深度的模型上增加更多的层会导致更高的训练误差，图1 展示典型的例子：随着深度的加深，误差也变大了。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/tuihua.png" style="zoom:67%;" />

训练精度的降低表明并不是所有的系统都同样容易优化，让我们考虑一个较为浅的结构以及向其添加更多的层的对应的部分。对于更深层次的模型，对于深层的模型，存在着一个通过*结构解决*的方案：添加的层是身份映射，而其他的层是从学习过的浅模型中复制的。这个构造的解的存在表明一个更深的模型应该不会产生比它的浅层对应的更高的训练误差。但是实验表明当前还没有办法找到比*结构解决*方案更好的解决办法(或者说无法在可行的时间内完成)。

在本文中，我们通过引入一个深度残差学习框架来解决退化问题。我们不是希望每几个堆叠层直接适合所需的底层映射，而是显式地让这些层适合残差映射。用公式来表示就是：将期望的底层映射记作$H(x)$，让堆叠的非线性层适合另一个映射：$F(x) := H(x) - x$ ，原始的映射就变成了$F(x)+x$我们假设优化残差映射比优化原始的、无参考的映射更容易优化。在极端情况下，如果一个恒等映射是理想的，那么将残差推到零比用一堆非线性层来拟合恒等映射要容易得多.

公式 $F(x)+x$ 可以通过短路连接的前馈神经网络实现：

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/shortcut.png" style="zoom:67%;" />

短路连接是那些跳过一个或多个层的连接。在我们的例子中，短路连接简单地进行了身份映射，并且它们的输出被添加到堆叠层的输出中。identity短路连接既不增加额外的参数，也不增加计算复杂度。整个网络仍然可以通过带有反向传播的SGD进行端到端的训练，并且可以使用公共库轻松实现，而无需修改求解器。

我们在ImageNet上进行了全面的实验，展示了退化问题，并评估了我们的方法。我们发现：1）我们的极端深度残差网络很容易优化，但是对应的普通网络（堆叠的那些层）在深度增加时表现出了更高的训练误差。2）我们的深度残差网在深度增加时可以很容易地提高精度，产生的结果远远好于以前的网络。

相似的现象也存在于CIFAR-10数据集上，证明我们模型的优化的困难和优点不止局限于特定的数据集。我们在此数据集上展示了超过100层的成功训练的模型，而且探索了超过1000层的模型。

在ImageNet分类数据集上，利用极深的残差网得到了很好的结果。我们的152层残差网罗是有史以来ImageNet上最深的网络，同时仍然比VGG网络有更低的复杂性。我们的网络在ImageNet测试集上排名前五的误差有3.57%。并在2015年分类竞赛ILSVRC中获得第一名。此极深的表征在其他识别任务上也有很好的泛化性能，lead us to further win the 1st places on: ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation in ILSVRC & COCO 2015 competitions。这有力的证据表明，残差学习原则是通用的，我们期望它适用于其他视觉和非视觉问题。

### 2.相关工作

**残差表征** 在图像识别中，VLAD是通过残差向量对字典进行编码的表示，Fisher向量可以表示为VLAD的概率版本。它们都是用于图像检索和分类的强大的浅层表示，对于向量量化，编码残差向量比编码原始向量更有效。

在低级视觉和计算机图形学中，为解决偏微分方程(PDEs)，广泛使用的多重网格方法将系统重新化为多尺度下的子问题，每个子问题负责在较粗尺度和较细尺度之间的残差解。多网格的另一种选择是分层基础预处理，依赖于表示两个尺度间残差向量的变量。。。。。

。。。

**短路连接** 关于短路连接的实践和理论已经被研究了很长一段时间，训练多层感知机的早期实践就是添加一个从网络输入到输出的线性层。在一些工作中，一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸问题。。。。。

与我们的工作同时，“高速网络”[42,43]提供了具有门控功能的短路连接



### 3.深度残差学习

#### 3.1 残差学习

让我们把H(x)看作一个底层映射，它适合几个堆叠层(不一定是整个网络)，而x表示这些层中的第一层的输入。如果假设多个非线性层可以逐渐逼近复杂的函数，就等同于假设他们可以逼近残差函数：$H(x) - x$ （假设输入和输出维度相同）。所以，我们不是期望堆叠的层去逼近$H(x)$ ，而是是这些层去逼近一个残差函数：$F(x) := H(x) - x$，所以原来的函数就变成了$F(x)+x$ （即，$F(x)$ 是堆叠层的输出，$F(x)+x$ 是残差层的输出）。尽管两种形式都应该能够渐近地近似所期望的函数(如假设的那样)，但学习的容易程度可能不同。

这种重新表述的动机是退化问题的反直觉现象。正如我们在引言中所讨论的，如果添加的层可以被构造成身份映射，那么更深的模型的训练误差应该不会比更浅的模型更大。退化问题表明，使用多个非线性层逼近身份映射时会遇到困难。根据残差学习重公式，如果恒等映射是最优的，求解者可以简单地将多个非线性层的权值趋近于零来逼近恒等映射。

在实际情况下，身份映射不太可能是最优的，但我们的重新规划可能有助于预设问题。如果最优函数更接近恒等映射而不是零映射，那么求解者应该更容易找到恒等映射的误差，而不是学习新的函数。我们通过实验表，学习后的残差函数一般具有较小的响应，这表明恒等映射提供了合理的前置条件。

#### 3.2 直连的身份映射

每隔几层进行残差学习，定义为：
$$
y = F(x,\{ W_i \}) + x
$$
这里x和y是所考虑的层的输入和输出向量。函数$F(x,{W_i})$ 代表要学习的残差映射。在图二中有两层，$F =W_2\sigma(W_1x)$  ,$\sigma$ 代表ReLU函数，而且为了简化省略了偏差。操作F + x是通过快捷连接和按元素添加来执行的。在添加之后我们使用了第二个非线性函数（$\sigma(y)$）

快捷连接既不引入额外的参数，也不引入计算复杂度。这不仅在实践中很有吸引力，而且在我们比较普通网络和剩余网络时也很重要。我们可以公平地比较同时具有相同数量的参数、深度、宽度和计算成本的普通/剩余网络

公式（1）中的x 和 F 的维度必须是一样的，如果不一样（比如改变了输入或输出的通道数）我们可以通过快捷连接实现线性投影Ws来匹配维度
$$
y = F(x, \{W_i\}) +W_sx
$$


#### 3.3 网络架构

我们测试了各种原始和残差网络，发现了一致的现象。为了提供实例供讨论，我们如下描述了ImageNet的两个模型。

**原始网络** 原始网络主要是受VGG网络的启发，卷积层大部分是有3$\times$3 的卷积核而且遵循以下两个规则：（1）对于相同的输出特征图大小，这些层都有相同数量的的卷积核（卷积核数量对应输出的通道数）；（2）如果feature map的大小减半，则将filter的数量增加一倍，以保持每层的时间复杂度。直接通过stride为2的卷积层来进行下采样。网络最后进行一次平均池化并采用softmax的1000路全连接层。所有的权重曾数量为34层。

值得注意的是，我们的模型比VGG网络具有更少的卷积核和更低的复杂性。我们的34层baseline有36亿次浮点运算(加和乘)，这只是vga -19(196亿次)的18%。

**残差网络** 在上述平面网络的基础上，我们插入快捷连接使网络变成对应的残差版本。当输入和输出的维度相同时，可以直接使用标识快捷连接（图中的实线）。当维度增加时(图中的虚线捷径)，我们考虑两种选择:（A）这个快捷方式仍然执行标识映射，用额外的零填充以增加维数。此选项不引入任何额外参数;（B）使用公式(2)中的投影快捷方式用于匹配维数(通过1$\times$1卷积完成)。对于这两种形式，都将特征图大小缩小一倍，应用stride为2的卷积。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/resnet.png" style="zoom:77%;" />





#### 3.4 应用

在ImageNet上的试验：对输入图像进行resize，使其短边随机为[256，480] 上的值来进行增强。从一幅图像或其水平翻转中随机裁剪224$\times$224的图片，并减去每个像素的平均值。同时还使用了标准颜色增强。在每个卷积之后和激活层之前，使用BatchNormalization。初始化权重并从头开始训练两种网络。我们使用的SGD的小批量尺寸为256。学习率从0.1开始，当误差趋于稳定时，学习率被除以10，并且模型被训练多达$60\times10^4$次迭代.我们使用了0.0001的权重衰减和0.9的动量,不使用dropout。

测试时，为进行研究的比较，采用标准的10-crop测试。为了得到最好的结果，我们采用[41,13]中的全卷积形式，在多个尺度上对分数进行平均(将图像进行缩放，使较短的一侧位于[224;256;384;480;640]中。

### 4. 实验

#### 4.1 ImageNet 分类

我们在ImageNet 2012分类数据集上评估了我们的方法，该数据集包含1000个类。模型在128万张训练图像上进行训练，在50k张验证图像上进行评估，我们还获得了由测试服务器报告的100k测试图像的最终结果。我们评估了前1和前5的错误率。

**原始网络** 我们首先评估18层和34层的原始网络。34层网络如上图所示。18层的网络也是类似的形式。参见表1了解详细的架构。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/all.png" style="zoom: 80%;" />

表2的结果表明，较深的34层纯网验证误差高于较浅的18层纯网验证误差。为了揭示原因，在图4(左)中，我们比较了它们在训练过程中的训练/验证错误。我们已经观察到退化问题--在整个训练过程中，34层原始网络的训练误差较大，尽管18层网络的解空间是34网络的解空间的子空间。



<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/18-34.png" style="zoom:77%;" />



<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/restrain.png" style="zoom:80%;" />

我们认为这种优化困难不太可能是由于梯度消失造成的。这些原始网络使用BN进行训练，保证前向传播的信号具有非零方差。我们还验证了反向传播的梯度具有BN的健康规范。所以前向信号和反向信号都不会消失。事实上，34层的网络仍然能够达到竞争精度(表3)，说明求解器在一定程度上是有效的。我们推测较深的原始网络可能具有指数级低的收敛率，这影响了训练误差的降低。造成这种优化困难的原因将在今后进行研究。

**残差网络** 

接下来我们评估18层和34层的残差网(ResNets)。基线架构与上面的普通网相同，只是如图3所示，在每一对3$\times$3 卷积核中添加了一个快捷连接(右)。在第一个比较中(右表2和图4)，我们对所有的快捷方式和增加维度的补零都使用了标识映射(选项A)。因此，与普通快捷方式相比，它们没有额外的参数。

在表2和图4中，主要有三个结论。首先，34层的网络比18层的网络表现变好了。更重要的是，34层的ResNet显示出相当低的训练错误，并可推广到验证数据。这表明在这样的设定中退化问题得到了很好的解决，并且我们设法通过增加深度来获得精度增益。第二，resnet相比原始网络，错误率降低了3.5%（表2），结果成功地减少了训练误差。这个比较证明了了残差学习在极深系统上的有效性。最后，我们还注意到，18层原始/残差网具有相似的精度(表2)，但是18层的ResNet收敛速度更快。当网络“不是太深”(这里是18层)时，当前的SGD解决方案仍然能够找到原始网络的较好的解决方案。在此案例中，ResNet通过在早期提供更快的收敛速度来简化优化。

**Identity vs. Projection Shortcuts**  （上面提到的shortcut维度不同时的两种解决方案）

对于公式2的方法，在表3中，我们比较了三个选项：（A）增加维度都用0来填充，并且所有快捷连接都是无参数的（上面已经提到），（B）增加的维度用投影快捷连接来填充，其他快捷连接为identity;（C）所有shortcut都是投影

表3显示了所有这三个选项都比普通选项好得多。B比A稍微好一点。我们认为这是因为A中的零填充维数确实没有残差学习.C比B稍微好一点，我们将此归因于许多(13条)投影捷径引入的额外参数。但是A/B/C之间的小差异表明投影shortcut对于解决退化问题不是必需的。因此，在本文的其余部分中，我们不使用选项C，以减少内存/时间复杂度和模型大小。标识快捷链接对于不增加下面介绍的瓶颈架构的复杂性特别重要。

**更深层次的瓶颈架构**

接下来，我们将描述ImageNet的更深层次的网络。由于考虑到我们能够负担的培训时间，我们修改了构建块作为瓶颈设计。对于每个残差函数F，我们使用3层堆栈而不是2层（图5）。这3个层是1$\times$1，3$\times$3，1$\times$1的卷积，1$\times$1的层负责减少和增加(恢复)维度（通道）。让3$\times$3层成为输入/输出维度更小的瓶颈。图5给出了一个例子，其中两种设计具有相似的时间复杂度。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/bolcks.png" style="zoom: 80%;" />

无参数标识快捷连接对于瓶颈架构尤其重要，如果用投影代替图5(右)中的identity shortcut，可以看出，由于shortcut连接到两个高维端点，时间复杂度和模型大小都增加了一倍。因此，identity shortcut使瓶颈模型带来了更有效。

**50-layer ResNet** 将34层网络中的两层的块用3层瓶颈块代替，就得到了50层的resnet（见表一）。我们使用选项B来增加维度。这种模式有38亿次运算。

**101-layer and 152-layer ResNets**  我们使用更多的3层块构造了101层和152层的ResNets。值得注意的是，尽管深度显著增加，152层ResNet(113亿次运算)的复杂度仍然低于VGG-16/19 net(153 / 196亿次)

50/101/152层的ResNets比34层的更加精确，我们没有观察到退化的问题，因此享受显著提高深度的精度。深度的好处在所有的评估指标中都是显而易见的。

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/rable3-5.png)



#### 4.2 CIFAR-10数据集上的分析

我们在CIFAR-10数据集进行了更多的研究，它由10个类的50k训练图像和10k测试图像组成。我们给出了在训练集上训练的实验和在测试集上评估的实验。我们关注的是极深的网络的行为，而不是推动最先进的结果，所以我们有意使用以下简单的架构

原始网络和残差网络结构按照图3中的结构。网络输入是32$\times$32的图像，用每像素减去平均值。第一层是3$\times$3的卷积层。然后在size为分别{32，16，8}的特征图上应用有6n个层的堆栈的3$\times$3的卷积，每个特征图大小有2n个层。对应的卷积核分别是{16，32，64}。下采样由步长为2的卷积执行。网络的最后是一个平均池化加一个10个参数的全连接层和softmax。总共有6n+2个叠加的权重层。

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/cif.png)

当使用快捷连接时，它们被连接到每对3$\times$3的层上(总共3n个快捷连接)。在这个数据集中，我们使用标识快捷连接(选项A)，因此，我们的残差模型具有与普通模型完全相同的深度、宽度和参数数量。

我们采用权值衰减为0.0001，动量为0.9，采用权重初始化和BN，不用dropout。这些模型在两个gpu上用batchsize为128的minibatch进行训练。开始时使用学习率为0.1，在32K和48K次迭代时除以10，训练在64K迭代后中止。我们遵循[24]中简单的数据扩充来进行训练:每边填充4个像素，从填充的图像或其水平翻转中随机采样32$\times$32的裁剪。为了进行测试，我们只对原始32$\times$32图像的单个视图进行评估。

比较了 n = {3,5,7,9}时的网络，分别对应的是20，32，44和56层。图6(左)显示了普通网络的行为，普通网络的深度越深，训练误差越大。图6(中间)显示ResNets的行为。同样与ImageNet的情况类似(图4，右)，我们的ResNets克服了优化的困难，并证明了当深度增加时，精度有所提高。

n = 18时，深度为110，在这种情况下，我们发现初始学习率为0.1有点太大，无法开始收敛。所以我们使用0.01开始，直到训练误差低于80%(约400次迭代)，然后回到0.1继续训练。学习率的其余部分和前面一样。这个110层的网络收敛得很好（中间的图）。 相比其他模型（fitNet，Highway等），它的参数更少模型更小，

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/fi6.png)

以下的一些分析不太重要，自己看即可。