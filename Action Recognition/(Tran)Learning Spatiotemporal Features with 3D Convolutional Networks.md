

### 摘要

我们提出一种简单而有效的方法来学习时空特征，使用深度三维卷积网络(3D ConvNets)在大规模监督视频数据集上训练。本文有以下3个发现：1）3D 卷积网络比2D网络更适合时空特征提取。2）对于所有的3DCNN结构来说，使用3$\times$3$\times$3的卷积核的同质架构是表现最好的；3）提出了C3D结构：这是一个简单的线性结构，在4个标准数据集中表现优于当前sota方法，同时在另外两个标准上与最优方法进行了比较。另外，它的特征很紧凑：在只有10个维度的UCF101上达到了52.8%的精度，同时由于卷积网络的快速推理，计算效率也非常高。它们在概念上非常简单，易于训练和使用。

### 引言

在行为识别，异常行为检测和活动理解等视频领域，在单独的问题上通过采取不同的方法，已经取得了很大的进展。然而，对于以同质方式解决大规模视频任务的通用视频描述符的需要仍然在增长。

一个有效的视频描述符有四个属性: (i) 通用性，这样它既就可以很好地表示不同类型的视频，同时还具有区别性。(ii) 紧凑性。（iii）高效计算；（iiii）容易部署。

本文中提出利用深度3DCNN来学习时空特征。实验数据表明，这些使用简单分类器学习到的特征能在各种视频分析任务中表现出良好的性能。

本文的贡献：

- 通过实验表明3D 卷积深度网络是一种能够同时模拟外观和运动的特征学习机器。
- 在有限的结构探索中通过经验发现在所有层中都使用3$\times$3$\times$3的卷积核是最好的。
- 在4个不同的任务和6个不同的基准上，这个简单的线性模型所提取的的特征优于或接近目前最好的方法

### 相关工作

小综述

### 用3D卷积网络学习特征

本节解释了3DCNN 的细节，经验上分析了不同的结构，详细说明如何在大规模数据集上训练它们以进行特征学习。

#### 3D卷积和池化

二维卷积应用于一幅图像会输出一幅图像，二维卷积应用于多幅图像(将它们视为不同的通道)也会得到一幅图像，只有3D网络会提取时间信息

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/2dvs3d.png)

**注释：**用c $\times$ l$\times$ h $\times$ w来表示视频片段：c 是通道数；l是帧长度。d$\times$k$\times$k 表示卷积核

**通用的网络设置： ** 描述我们训练的网络的相同的网络设置，这些网络被设置为以短视频切片作为输入，输出预测的101种不同动作对应的类别标签。所有的视频帧都被设置为128$\times$171大小，大概是UCF101帧分辨率的一半。把视频分割成16帧的不重叠片段，然后作为网络的输入，输入为3$\times$16$\times$128$\times$171。训练时也使用输入的随机切片，大小为3$\times$16$\times$112$\times$112 来作为抖动。网络有5个卷积层和5个池化层（每个卷积后面跟一个池化），两个全连接层和1个softmax损失层来预测动作标签。每个卷积的卷积核数量为为64，128，256，256，256。这些卷积核的时间深度d稍后解释。所有的卷积都采用合适的padding（卷积核1对应了1）（时间和空间）以及stride为1，来保证每层输出的维度与输入相比不变。所有的池化层都是stride=1，2$\times$2$\times$2的最大池化（除了第一层）从而使输出比输入减小了8倍。第一个池化层为1$\times$2$\times$2，目的是为了不过早合并时间信号，也为了满足16帧的剪辑长度（16帧进行4次减2倍就成1了）。两个全连接层有2048个输出，使用mini-batches为30的输入，学习率为0.003，训练16 epoch。

**结构间的不同之处：** 我们只改变卷积层的核时间深度$d_i$，而保持所有其他常见设置如上所述的固定不变。我们试验了两种类型的架构：1）相同的时间深度：所有的卷积核使用通向的深度；2）不同的时间深度：不同层之间的深度不同。对于第一种，分别令d = 1,3,5,7 做了四种实验，将这些网络命名为**depth-d**，其中d就是深度。注意depth-1网络就相当于在不同的帧中使用2D卷积。第二种方式，试验了两种网络：深度递增 3-3-5-5-7和递减7-5-5-3-3。我们注意到，所有这些网络在最后的池化层有相同大小的输出，因此对于全连接的层，它们有相同数量的参数。它们的参数数只是在卷积层上因核的时间深度不同而有所不同。与全连接的层中的数百万个参数相比，这些差异是相当微小的。比如任意两个深度差2的网络之间只差17K个参数，depth-1和depth-7差51K个参数，但也只是总参数的的0.3%。这表明网络的学习能力是可比较的，参数数量的差异不应该影响我们的架构试验结果。

### 探索核深度

结果表明核深度为3，即使用3$\times$3$\times$3的卷积核效果最好。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/depth.png" style="zoom: 67%;" />

### 时空特征学习

**网络结构： ** 已经证明3$\times$3$\times$3的卷积核是最优的，所以可以根据机器的内存限制和计算能力在大规模数据集上训练尽可能深的网络。根据当前GPU的内存，我们设计的C3D网络有8个卷积层，5个池化层，2个全连接层和一个softmax输出层。所有的卷积核都为3$\times$3$\times$3，stride为1。池化的核第一个为1$\times$2$\times$2，其他四个为2$\times$2$\times$2。

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/C3D源.png)

**数据集：** 为了提取时空特征，在 Sports-1M数据集上训练C3D，这是目前最大的视频分类基准。包括110万运动视频，487个动作分类，相对于UCF101有5倍的类别和100倍的视频数量。

**训练：** 由于Sports-1M有很多长视频，我们从每个训练视频中随机抽取5个2秒长的片段，然后将片段大小设置为128$\times$171。训练过程中又随机把片段切割为16$\times$112$\times$112的形状来进行时空抖动。同时以50%的概率进行水平翻转。使用SGD优化，bath为30。初始学习率为0:003，每150K次迭代除以2。1.9M次迭代(大约13个epoch)时停止优化。除了从头开始训练C3D网络，我们也实验了从I380K上预训练的模型调优的C3D网络。

**Sports-1M分类结果：** 下表展示了C3D与其他两种网络结果的比较。 对于每个视频片段，我们只用了中心剪切，然后通过网络进行片段的预测。对于视频预测，我们对随机从视频中提取的10个视频片段的预测进行平均。

![](https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/fenleijieguo.png)

值得注意的是，两种比较方法在设置上存在一些差异。DeepVideo和C3D使用短的视频片段而Convolution pooling使用长片段。DeepVideo使用了更多的裁剪：每个片段4个裁剪，每个视频80个裁剪；而C3D分别是1个和10个。

**C3D视频描述符：** 经过训练，C3D可以作为特征提取器用于其他视频分析任务。为了提取C3D特征，将一个视频分割为16帧长的片段，两个连续的片段之间有8帧的重叠。这些片段擦混入网络来提取fc6层的激活信息。这些信息平均成4096维的视频描述符，然后进行L2正则化。在所有实验中都称这些为C3D视频描述符（特征）

**C3D学习的是什么？** 

我们使用[46]中解释的反卷积方法来理解C3D内部学习的内容。我们观察到C3D刚开始聚焦于前几帧的外观，在随后的帧中跟踪显著的运动。下图通过把最高的激活结果投射回图像空间来展示了C3D的两个conv5b层的反卷积。在第一个例子中，刚开始聚焦于整个人的特征，在以后的帧中追踪撑杆跳的动作。同样的，在第二个例子中，它首先聚焦在眼睛上，然后在化妆时跟踪眼睛周围发生的运动。因此，C3D与标准2D ConvNets的不同之处在于，它选择性地兼顾运动和外观。

### 行为识别

**数据集：** 我们在UCF101上评估C3D特征，此数据集包含101类人类动作类别的13320个视频。我们使用此数据集提供的三分割设置

**分类模型：** 提取C3D特征并将其输入到多类线性支持向量机来训练模型。我们使用3种不同的网络来实验C3D描述符：在I380K上训练的C3D，在Sports-1M上训练的C3D，以及在I380K上训练的并在Sports-1M上微调的C3D。在多网络设置中，我们将这些网络的L2正则加C3D描述符连接起来。

**Baselines：** 我们将C3D与很多Baselines进行了比较：目前最好的基于手工的特征，即改进密集轨迹(iDT)和常用的深度图像特征，即Imagenet,使用Caffe的预训练模型。

**结果： ** 下表给出了C3D相对于两种基线和目前最佳方法的动作识别准确率。上面的部分显示了两个基线的结果。中间部分展示了只使用RGB帧作为输入的方法。下面的部分报告了目前使用所有可能的特征组合的所有最佳方法

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/c3dbijiao.png" style="zoom:67%;" />

### 剩下的是C3D在其他数据集上的其他一些应用

