### 摘要

之前的目标检测使用分类器来执行检测。但是我们将目标检测看作是空间分离的边界框和相关的类的概率的回归问题。一个单独的网络在一次测试中直接从完整的图像中预测边界框和类别的概率。由于整个检测过程是一个单一网络，因此可以对其检测性能进行端到端的直接优化。

基础模型一秒可以处理45帧图像，Fast版本更快同时mAP可以达到其他检测器的两倍。与sota模型相比，YOLO有更多的局部误差，但是不会预测出假阳性。

### 引言

当前的检测系统使用分类器来执行检测，为了检测一个目标，这些系统对该目标进行分类，并在测试图像的不同位置和尺度上对其进行评估。像DPM这样的系统，使用滑动窗口的方法，将分类器在整个图像中均匀间隔的位置上运行。

R-CNN使用候选区域的方法，首先在图像中生成可能是目标的边界框，然后在这些候选区域上进行分类。分类完成后，通过后处理对边框进行细微调，消除重复的检测，并根据场景中其他物体对边框重新打分。这些复杂的过程速度很慢，而且很难优化，因为每个单独的组件都必须单独训练。

我们将目标检测重构为一个单一的回归问题，直接从图像像素到边界盒坐标和类概率。

YOLO：使用一个卷积网络同时预测多个边界框和这些边框对应的类别概率。YOLO在全图像上训练并且直接优化检测性能

与传统的目标检测方法相比，这种统一的模型有几个优点：

1. 非常快，同时YOLO达到了其他实时系统平均精度的两倍以上。
2. YOLO在做预测的时候从整体上对图片进行分析。不像滑动窗口和候选区域的方法，YOLO在训练和测试时是针对整个图像，因此它隐式地编码有关类及其外观的上下文信息。Fast R-CNN将图像中的背景补丁错误地当成物体，因为它看不到更大的背景。YOLO产生的背景错误少于Fast R-CNN的一半。
3. YOLO学习对象的通用的表征，当在自然图像上训练并在艺术品中测试时，性能仍然很好。

YOLO在准确度方面仍然落后于最先进的检测系统。虽然它可以快速识别图像中的物体，但它很难精确定位一些物体，特别是小物体。我们在实验中进一步研究了这些权衡

### 2. 整体的检测

我们将目标检测的各个部分统一到一个单一的神经网络中，我们的网络使用来自整个图像的特征来预测每个边界框。它还可以同时预测图像中所有类的所有边框。这意味着我们的网络在整体范围内对整个图像和图像中的所有对象进行分析。

将输入分为$S\times S$ 的网格。如果一个物体的中心落在一个网格里，这个网格就负责检测这个物体。

每个网格预测B个边界框和这些框的信心分数。这些分数反映了模型对边框里有一个物体的置信程度，也反映了模型对边框预测的准确度。我们将此置信度定义为$Pr(Object)*IOU^{truth}_{pred}$  。如果网格内没有物体，分数为0。否则就令此分数等于预测的边框和真实边框的交并比。

