## 摘要wei



视频动作识别广泛应用于视频检索，智能监控，多媒体理解以及其他领域。近年来，通过引入卷积神经网络对深度信息的学习，该算法得到了极大的改进。这驱使我们回顾了有名的基于CNN的动作识别工作。由于CNN主要设计来从静止图像中提取二维空间特征，视频自然被视为3维信号，因此将CNN从图像扩展到视频的核心问题是时间信息的挖掘。我们将开发时间信息探索的解决方案分为三种策略：1）3D CNN；2）将与动作有关的信息作为CNN 的输入；3）融合。在本文中，我们根据这些策略对基于CNN的动作识别方法进行了全面的综述。我们还讨论了动作识别在最近的大规模基准的性能和基于CNN的行为识别的局限性以及未来的研究方向。本文对基于CNN的行为识别进行了客观而清晰的综述，并为今后的研究提供了指导。

## 1. 引言

识别和理解人类的行为和意图在机器人技术、人机交互、智能监控等领域是至关重要的，而且因此成为了一个重要且流行的研究课题。在过去的几十年中，大量的视频行为识别方法涌现出来。此外，各种行为识别数据集和标准也都发布了出来。2012年以来，卷积神经网络被广泛应用于图像领域，显著提升了图像分类，目标检测，场景分类的性能。CNN在图像领域的成功激起了其在视频行为检测上的研究。从图像扩展到视频的方法和CNN架构取得了显著成果。因此，基于CNN 的行为识别成为了一个热门的研究领域，近年来出现了大量基于CNN的方法，这些方法也取得了很大的成功。

如图一所示，视频行为识别分为两种任务：将视频分给一组事先定义好的动作类别中，以及在视频中定位实现定义好的动作，这两个任务分别叫分类和检测。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/分类和检测.png" style="zoom:67%;" />

与可视视频（灰度或RGB视频）相比，深度视频对光照不敏感并且可以捕捉物体的几何信息，而红外热成像视频对池成像光，光照变化等具有鲁棒性。此外，通过部署多目摄像头，可以从不同视角获取信息，从而使行为识别更加准确。因此，在深度视频，红外热成像视频和多角度视频中的行为识别获得了很大关注，而且在这些方向已经有了应用。

很明显，基于CNN的行为识别可以从可视视频扩展到深度视频和红外视频，从单视角到多视角。分类作为最基本和重要的任务，已经被广泛、深入地研究过，现在被归入检测的任务中。因此，这篇综述重点说明了可视单目视频中的动作分类任务。

本文按以下结构做了基于CNN的行为识别综述：第2节介绍先前的综述工作，第3节从手工方法和深度学习方法对行为识别做了综述。第4节根据挖掘时间信息的解决方案全面回顾了基于CNN的行为识别。第5节介绍当前发布的大规模行为识别数据集并且讨论了在这些标准上基于CNN 的动作识别的表现。最后，第6章总结CNN动作识别的局限性和未来的研究方向。



## 2.此前的综述工作

目前已经有很多文献对行为识别做了综述，有些作品明显包括最近的行为识别方法。有的文献专门讨论了行为识别的数据集和标准。本节我们介绍2014年以来发表的行为识别方向的综述。

。。。

介绍综述，就不翻译了



## 3. 行为识别综述

典型的行为识别分为两步：动作表征和分类。动作表征，也就是特征提取，被认为是行为识别的核心。高效的动作表征应该有以下特点： 1）有区别度：来自相同类的动作表征携带相似的信息，而来自不同类的动作表征携带不同的信息。2）效率：动作特征容易计算。 3）低维：这会使分类的成本低并且节省特征

图二表示了基于动作特征的行为识别分类，将行为识别分为手工表示和深度学习表示的方法，分别从视频中提取已经设计好的特征和可训练的特征，这两种方法的框架见图三

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/行为识别分类.png" style="zoom:67%;" />

<center>图二</center>

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/手工和深度.png" style="zoom:67%;" />

<center >图三</center>

对行为识别的研究开始于80年代对整体表征的研究，这种方法提取全局特征，比如基于轮廓的特征和基于光流的特征。然而，由于摄像头的抖动或运动，这种方式有一定的限制，需要进行背景背景减影，前景提取，定位和跟踪等预处理。2003年以来，局部表征的方法在行为识别上表现良好，这种方式直接从感兴趣点中提取特征，从而避免了预处理。手工表示的方法是行为识别中的一个里程碑。有关改进密集轨迹（IDT）的相关工作，这些研究使用Fishier vector(FV)或者超混合向量（HSV）来编码提取的密集轨迹、轨迹对齐HOG、HOF、和MBH，从而实现了手工表征行为识别的最好性能，而且经常用作评估新的额深度学习方法的标准。

不同于手工表示的方法，手工表示是使用手工设计好的特征，深度学习表征方法自动在视频中学习可训练的特征。图二给出了基于深度学习分类的深度学习行为识别类别。在计算机视觉的各个领域，包括行为识别基于深度学习的方法是目前研究的最多的方法，并且已经取得了很大的成功。除了CNN，其他的深度学习方法也被应用到动作识别中，并取得了很好的效果，尽管它们目前还不是很流行。这里，我们给出了每个类别的例子。Taylor等人使用限制玻尔兹曼机来获取各种基于运动的动作特征；Baccouche等人提出了一种自动学习稀疏超时空特征的自编码模型；Chen等人使用深度信念网络模型从视频中学习恒定的时空特征；为了探索各种卷积时间特征池化结构并将视频作为帧的有序序列进行建模，veeriah等人采用循环神经网络（RNN）也就是长短时记忆（LSTM）来学习复杂的动态行为。此外，Le等人提出一种独立子空间分析（ISA）网络算法的扩展，来从视频中学习恒定的时空特征。

## 4. 基于CNN 的行为识别



卷积神经网络是一种生物学启发的多层感知的变体，是一种前馈人工神经网络。它包括一个输入层，一个输出层和多个隐藏层。隐藏层是卷积层、池化层或全连接层。卷积层对输入数据应用卷积操作并添加偏差，并将结果首先通过一个激活函数然后传递给下一层。池化层是一种非线性的下采样层。在卷积层和池化层之后，CNN中的高级推是在全连接层中进行的，全连接层的每个神经元都连接到前一层的激活函数。在第 $i$ 层的第 $j$ 个特征图（feature map）在$（x,y）$ 处的计算如公式（1）所示
$$
v_{il}^{xy} = \varphi(b_{i,j}+\sum_m\sum^{P_i-1}_{p=0}\sum^{Q_i-1}_{q=0}w^{p,q}_{i,j,m}v^{(x+p),(yz=q)}_{(i-1),m})
$$
$\varphi$ 是一个非线性函数（比如Tanh,Sigmod或者ReLU）激活函数，W是权重矩阵，P和Q 是卷积核的高和宽

1998年一个名为LeNet-5的CNN结构被设计出来用以识别文件中的数字。然而，CNN发展的一直很慢，直到2012年在图像分类上开始迅速发展。近年来，CNN在图像分类和目标检测方面有了显著的发展。各种CNN结构比如ZFNet,VGG,GoogLeNet,BN-Inception和 ResNets等涌现出来，这些CNN架构的预训练模型(权值)是通过对大规模数据集进行预训练得到的。对于新的小规模数据集或新程序，可以部署迁移学习以微调网络的预训练模型。收到CNN在图像领域的启发，研究人员开始将CNN应用于视频行为识别领域。一大批表现良好的基于CNN 的行为识别方法涌现出来。

CNN 主要应用于二维空间，而且在提取静态图片的空间信息方面很有优势。一些研究使用CNN提取空间信息，并将它当作作辅助线索，和手工特征iDT结合起来以实现最后的行为识别。然而，视频作为3维时空信号，CNN主要是用来提取空间特征的，所以CNN由于缺乏时间信息不适合应用于视频。因此，将CNN从图像扩展到视频的核心问题是对时间信息的利用。我们将时间信息开发的解决方案分为三种策略：1）3D CNN；2）将与动作有关的信息作为CNN 的输入；3）融合。事实上，这三种方法是互相重叠的，比如一种 3D CNN结构也使用运动信息作为它的输入。

### 4.1 3D 卷积

利用时空信息最直接的解决方案是对视频进行3D卷积，这在2012年之前的一些开创性的基于CNN 的动作识别作品中得到了验证。3D卷积是通过使用3D卷积核对视频片段进行卷积实现的。在第i个卷积层的第j个特征图上（x,y,z）处的运算如公式二：

$$
v_{il}^{xy} = \varphi(b_{i,j}+\sum_m\sum^{P_i-1}_{p=0}\sum^{Q_i-1}_{q=0}\sum^{R_i-1}_{r=0} w^{p,q,r}_{i,j,m}v^{(x+p),(y+q),(z+r)}_{(i-1),m})
$$
其中，R 是时间长度，2D卷积和3D卷积示意图如下：

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/2d&amp;3d.png" style="zoom:67%;" />



Ji等人设计了一个用于行为识别的3D CNN网络，是2012年之前重要的开创性作品之一，它有1个硬线层，3个卷积层，2个下采样层和一个全连接层，硬线层生成灰度通道，梯度通道和光流通道。之后，在每个通道中应用卷积和下采样，最后的行为识别是通过结合所有通道的信息计算得到的。最近Ji等人改进了他们的3D CNN 网络，将输出的高级特征正则化，并且结合了多种不同CNN 结构的预测。与此同时，Tran等人做了系统的研究来寻找3D CNN的最佳卷积核的时间长度而且开发了一种VGG风格的3D CNN结构，名为C3D。如图5所示，C3D结构使用了8个卷积层以及$3\times3\times3$  的小卷积核，5个池化层和两个全连接层。此网络提取到的特征经过证明是通用的，而且高效、紧凑。此外，Tran等人在深度残差网络中进行了3D CNN 的研究，开发了一种ResNet18风格的网络，名为Res3D,在识别精度方面优与C3D.相比C3D, Res3D在运行时快2倍，在尺寸上小2倍，而且更紧凑。通过在最大的行为识别数据集Sports-1M上进行预训练，作者提供了C3D和Res3D的预训练模型，这些模型既可以用作迁移学习的初始化，也可作为固定的时空特征提取器。不同于以上提到的工作（在7，16或8帧的视频切片上学习时空信息），Varol等人开发了一种长时间时间卷积结构（LTC）,该结构通过在更长一点的视频片段上（比如60或者100帧）部署3D CNN在全时间尺度上表示动作，而且证明了高质量光流作为LTC输入的重要性。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/C3D.png" style="zoom:67%;" />

<center>图5 C3D结构 红色，绿色，蓝色，黄色和紫色的长条分别代表卷积，标准化，池化，全连接和softmax层

训练3D CNN非常耗费算力和内存，使用2D CNN模拟或仿真3D CNN是3D CNN的另一种实现方式。为了减少网络参数的数量，缓解高核复杂度和训练视频数据不足的多种困难，Sun等人提出了一种分解时空卷积网络（FstCN）,将原始的三维卷积核学习分解为先学习低层的二维空间卷积核，然后再学习上层的一维时间卷积核。针对序列对齐的问题，他们还提出了一种有效的训练和推断策略，该策略基于对给定动作视频序列中的多个视频片段进行采样。

为了使用2D CNN 的技术，而不是从头开始训练3D CNN，Mansimov等人提出了几种使用2D卷积权重去初始化3D卷积权重的方法，包括包括平化、缩放、零权重和负权重初始化。实验结果表明，在所有初始化方法中，负权值初始化的性能最好。包含时间维度 $T$ 的3D卷积权重矩阵$w^{p,q,r}$ 是由D卷积权重矩阵$w^{p,q}$ 负权重初始化得到的：


$$
w^{p,q,r} = \alpha_t w^{p,q},\text {where} \ \ \ \  \alpha = \begin {cases}
\frac{2 T-1}{T}, \ \ \  \ \text {if  t=1}\\
-\frac1T, \ \ \ \ \text {otherwise}
\end{cases}
$$


通过将一个$3\times 3 \times 3$ 的3D卷积滤波器分解成一个$1\times3\times3$ 的卷积滤波器（相当于2D CNN）和一个$3\times1\times1$ 的卷积滤波器（1维 CNN），Qiu等人在残差网络中设计了三种瓶颈结构的block，并且提出了一种名为 P3D ResNet 的伪3D Residual50结构，在该结构中残差单元被不同的构建块所替代，如图六所示。为了追求深度网络设计中的结构多样性，这三种变体以交错顺序混合。与原始的3D CNN相比，这个伪3D CNN不仅大大减小了模型的尺寸，而且可以在图像数据集上使用2D CNN 预训练。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/P3D.png" style="zoom:67%;" />

<center>图六 三种结构

### 4.2 将运动相关的信息作为 CNN 的输入

为了利用时间信息，一些研究已经在试着将运动信息比如光流和运动向量作为CNN的输入。如图7所示的双流模型，将光流作为CNN的输入来提取运动信息，是一种流行而且重要的动作识别方法。根据视觉通路假说：腹侧流在对象的感知识别中起主要作用，而背侧流则针对此类对象的视觉引导动作介导了所需的感觉运动转换，simonyan等人提出了行为识别的双流模型，空间流在静止的帧中精心行为识别，训练时间流从运动信息中进行动作识别。该模型中的每条流都采用CNN架构来实现，通过后期融合(均值融合或SVM融合)将两种流的softmax得分进行合并，得到最终结果。每个流都采用CNN-2048结构。由于空间流的CNN 本质上是一种图像分类，他们在ImageNet数据集上预训练了空间CNN，又在测试集种对空间CNN进行了微调。时间CNN不像空间CNN那样，可以在大型分类数据集上预训练，它需要在更小的测试集上训练。为了防止过拟合，采用多任务学习来对时间CNN进行训练。然而，双流法在动作识别方面的改进并不明显。Wang等人通过比较两流法和静止图像中的物体识别，认为产生这一结果有两个原因 :一是选取的CNN结构太浅，二是训练集的规模太小。为了解决这些问题，他们采用了GoogLeNet和VGG-16深度CNN 结构设计了一个非常深的双流模型，同时在训练时做了一些改进，包括对两个流都进行预训练，使用更小的学习率，更多数据增强和高dropout率。这个很深的双流模型比原始的模型表现要好。为了最大化利用双流模型中的时空信息，Feichtenhofer等人研究了很多种在时空上融合两种流的方法，提出了一种一种改进的双流模型，该模型在两个流之间引入了一种新的卷积融合层和一个包含了3D 卷积和3D池化的新型时间融合层。这种池化和其他类型的池化的区别如图8所示。由于最近在非常深的网络训练中使用ResNet表现很好，Feichtenhofer等人也引入了时空ResNet，作为ResNet和双流法的组合：通过在空间流和时间流之间加入残差连接，从而可以对时空特征进行分层学习。此外，通过将预训练模型的维映射过滤器转换为时间卷积，将两个流从空间域转换到时空域，并随时间初始化为残差过滤器。在这个双流模型中，计算光流是最消耗算力的。Zhang等通过将光流替换为运动向量来加速该模型，运动向量可以直接从压缩视频中得到而无需额外计算。然而，运动向量缺乏精细的结构，并包含噪声和不准确的运动模式。为了解决这个问题，他们提出将从光流CNN学习到的知识转移到运动矢量CNN，即对运动向量进行训练。

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/双流模型.png" style="zoom:67%;" />

<center>图7  双流模型 红、绿、蓝、黄、紫分别代表卷积、标准换、池化、全连接层和softmax层

<img src="https://raw.githubusercontent.com/liuzhaoo/markdown_pics/master/img/3D CON+3DPOLING.png" style="zoom:67%;" />

<center>图8 3D Conv + 3D Pooling与其他类型的比较 3D Conv + 3D Pooling在3D Pooling之前与一个跨越特征通道、空间和时间的融合内核进行卷积。

### 4.3 融合 